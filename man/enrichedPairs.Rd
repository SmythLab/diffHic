\name{enrichedPairs}
\alias{enrichedPairs}

\title{Compute local enrichment for bin pairs}
\description{Calculate the log-fold increase in abundance for each bin pair against its local neighbourhood.}

\usage{
enrichedPairs(data, flank=5, exclude=0, prior.count=2, abundances=NULL)
}

\arguments{
\item{data}{a \code{DIList} object containing bin pair counts, generated by \code{\link{squareCounts}}}
\item{flank}{an integer scalar, specifying the number of bins to consider as the local neighbourhood}
\item{exclude}{an integer scalar, specifying the number of bins to exclude from the neighbourhood}
\item{prior.count}{a numeric scalar indicating the prior count to use in computing the log-fold increase}
\item{abundances}{a numeric vector of abundances for each bin pair}
}

\section{Definition of the neighbourhoods}{
Consider the coordinates of the interaction space in terms of bins, and focus on any particular bin pair (named here as the target bin pair).
This target bin pair is characterized by four neighbourhood regions, from A to D.
Region A is a square with side lengths equal to \code{flank*2+1}, where the target bin pair is positioned in the center.
Region B is a square with side lengths equal to \code{flank}, positioned such that the target bin pair lies at the corner furthest from the diagonal (only used for intra-chromosomal targets).
Region C is a horizontal rectangle with dimensions \code{(1, flank*2+1)}, containing the target bin pair at the center.
Region D is the vertical counterpart to C.

% Segments C and D might be better than separate up/down/left/right neighbourhoods, as those run the risk of
% being too aggressive if the peak spills over into those neighbourhoods. Spillover is diluted a bit more
% when you consider up/down together or left/right together, which reduces the problem.
%
% Similarly, segment A is probably better than looking at each quadrant separately, as it dilutes out any
% other peaks in the neighbourhood. It fails to account for off-diagonal structural features, but there
% don't seem to be that many of them anyway, so maybe that's not an issue.

Obviously, the target bin pair itself is excluded in the definition of each neighbourhood.
If \code{exclude} is positive, additional bin pairs closest to the target will also be excluded.
For example, region A* is constructed with \code{exclude} instead of \code{flank}, and the resulting area is excluded from region A (and so on for all other regions).
This avoids problems where diffuse interactions are imperfectly captured by the target bin pair, such that genuine interactions spill over into the neighbourhood.
Spill-over is undesirable as it will inflate the neighbourhood abundance for genuine interactions.
Setting a larger \code{exclude} ensures that this does not occur.

The size of \code{flank} requires consideration, as it defines the size of each neighbourhood region.
If the value is too large, other peaks may be included in the background such that the neighbourhood abundance is inflated.
On the other hand, if \code{flank} is too small, there will not be enough neighbourhood bin pairs to dilute the increase in abundance from spill-over.
Both scenarios result in a decrease in enrichment values and loss of power to detect punctate events.
The default value of 5 seems to work well, though users may wish to test several values for themselves.
}

\section{Computing the enrichment values}{
For a target bin pair in \code{data}, the \code{enrichedPairs} function computes the mean abundance for each of its surrounding neighbourhoods.
This is defined as the mean of the counts for all constituent bin pairs in that neighbourhood (average counts are used for multiple libraries).
The local background for the target bin pair is defined as the maximum of the mean abundances for all neighbourhoods.
The enrichment value is then defined as the the difference between the target bin pair's abundance and its local background.
The idea is that bin pairs with high enrichments are likely to represent punctate interactions between clearly defined loci.
Selecting for high enrichments can then select for these peak-like features in the interaction space.

% If a peak is outside a TAD (but still within flank distance), then the TAD will be partially included in the 
% background. This could inflate the background abundance and prevent calling of the peak. To avoid this, you'd
% have to be able to specify the boundaries of the structures in the interaction space, which is complicated.
% However, most peaks seem to occur at the cap of domains anyway (or, most looping interactions generate their
% own domain) so it might not be likely to observe a peak outside of a domain. Ah well.

The maximizing strategy is designed to mitigate the effects of structural features.
Region B will capture the high interaction intensity within genomic domains like TADs, while the C and D will capture any bands in the interaction space.
The abundance will be high for any neighbourhood that captures a high-intensity feature, as the average counts will be large for all bin pairs within the features.
This will then be chosen as the maximum during calculation of enrichment values.
Otherwise, if only region A were used, the background abundance would be decreased by low-intensity bin pairs outside of the features.
This results in spuriously high enrichment values for target bin pairs on the feature boundaries.

By default, nothing is done to adjust for the effect of distance on abundance for intra-chromosomal bin pairs.
This is because the counts are generally too low to routinely fit a reliable trend.
That said, users can still supply distance-adjusted abundances as \code{abundances}.
Such values can be defined as the residuals of the fit from \code{\link{filterTrended}}.
Obviously, no such work is required for inter-chromosomal bin pairs. % Distance adjustment will have no effect, as the direct filtering threshold is constant for all bin pairs.
}

\value{
A numeric vector containing the log-fold increase (i.e., enrichment value) for each bin pair in \code{data}.
}

\author{
Aaron Lun
}

\seealso{
\code{\link{squareCounts}},
\code{\link{filterPeaks}}
}

\examples{
# Setting up the object.
a <- 10
b <- 20
regions <- GRanges(rep(c("chrA", "chrB"), c(a, b)), IRanges(c(1:a, 1:b), c(1:a, 1:b)))

set.seed(23943)
all.anchors <- sample(length(regions), 50, replace=TRUE)
all.targets <- as.integer(runif(50, 1, all.anchors+1))
data <- DIList(matrix(rnbinom(200, mu=10, size=10), 50, 4), anchors=all.anchors, 
    targets=all.targets, regions=regions, exptData=List(width=1))

# Getting peaks.
head(enrichedPairs(data))
head(enrichedPairs(data, flank=3))
head(enrichedPairs(data, flank=1))
head(enrichedPairs(data, exclude=1))

# Accounting for distance.
filtered <- filterTrended(data, prior.count=0)
adj.ab <- filtered$abundances - filtered$threshold
head(enrichedPairs(data, abundances=adj.ab))
}

\references{
Rao S et al. (2014). A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping. \emph{Cell}. 159, 1665-1690.
}

\keyword{filtering}
